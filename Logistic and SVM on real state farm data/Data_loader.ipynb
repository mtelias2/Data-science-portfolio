{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data_loader.ipynb\n",
    "### Author: moutaz elias\n",
    "\n",
    "Data_loader.ipynb takes care of loading the test and training data, explaratory analysis, cleaning the data (one hot encoding, feature extraction, and fill Nan), and spliting the training data into test and train k fold sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing relevant libraries\n",
    "#importing relevant libraries\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as pre\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os as os\n",
    "import pickle as pkl\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turning off warning and other jupyter specific options\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data directories and checking if they exist\n",
    "directory_train=\"../data/exercise_20_train.csv\"\n",
    "directory_test=\"../data/exercise_20_test.csv\"\n",
    "\n",
    "if not os.path.isfile(directory_train):\n",
    "    print(\"Training file does not exist\")\n",
    "if not os.path.isfile(directory_test):\n",
    "    print(\"Test file does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64    94\n",
      "object      6\n",
      "int64       1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x91</th>\n",
       "      <th>x92</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.963686</td>\n",
       "      <td>6.627185</td>\n",
       "      <td>-45.224008</td>\n",
       "      <td>9.477531</td>\n",
       "      <td>-3.216532</td>\n",
       "      <td>13.216874</td>\n",
       "      <td>9.754747</td>\n",
       "      <td>5.245851</td>\n",
       "      <td>-1.102918</td>\n",
       "      <td>-2.867482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988829</td>\n",
       "      <td>0.313772</td>\n",
       "      <td>asia</td>\n",
       "      <td>1.380664</td>\n",
       "      <td>-16.388994</td>\n",
       "      <td>5.326730</td>\n",
       "      <td>4.187294</td>\n",
       "      <td>0.045549</td>\n",
       "      <td>-3.646841</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.770062</td>\n",
       "      <td>-23.610459</td>\n",
       "      <td>-0.964003</td>\n",
       "      <td>-31.981497</td>\n",
       "      <td>-10.294599</td>\n",
       "      <td>-10.240251</td>\n",
       "      <td>-1.518888</td>\n",
       "      <td>-1.675208</td>\n",
       "      <td>0.498134</td>\n",
       "      <td>-0.614390</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.162863</td>\n",
       "      <td>1.809807</td>\n",
       "      <td>asia</td>\n",
       "      <td>2.500590</td>\n",
       "      <td>4.338834</td>\n",
       "      <td>-1.583225</td>\n",
       "      <td>-1.172417</td>\n",
       "      <td>0.011216</td>\n",
       "      <td>0.097180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.962401</td>\n",
       "      <td>-8.349849</td>\n",
       "      <td>23.248891</td>\n",
       "      <td>-24.196879</td>\n",
       "      <td>8.937480</td>\n",
       "      <td>10.965000</td>\n",
       "      <td>-7.490596</td>\n",
       "      <td>-3.025094</td>\n",
       "      <td>0.595807</td>\n",
       "      <td>0.382732</td>\n",
       "      <td>...</td>\n",
       "      <td>1.779660</td>\n",
       "      <td>9.528113</td>\n",
       "      <td>asia</td>\n",
       "      <td>1.396475</td>\n",
       "      <td>7.839188</td>\n",
       "      <td>10.402396</td>\n",
       "      <td>1.288991</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>-4.132316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.780709</td>\n",
       "      <td>-25.261584</td>\n",
       "      <td>1.383115</td>\n",
       "      <td>-11.786929</td>\n",
       "      <td>7.993078</td>\n",
       "      <td>-11.245752</td>\n",
       "      <td>-2.607351</td>\n",
       "      <td>-3.513896</td>\n",
       "      <td>-0.614235</td>\n",
       "      <td>-1.453979</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.203206</td>\n",
       "      <td>4.892248</td>\n",
       "      <td>asia</td>\n",
       "      <td>0.744317</td>\n",
       "      <td>7.380982</td>\n",
       "      <td>7.599323</td>\n",
       "      <td>-8.022884</td>\n",
       "      <td>-0.067624</td>\n",
       "      <td>-1.796198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.211541</td>\n",
       "      <td>1.119963</td>\n",
       "      <td>7.512938</td>\n",
       "      <td>21.987312</td>\n",
       "      <td>-5.155392</td>\n",
       "      <td>10.339416</td>\n",
       "      <td>3.045180</td>\n",
       "      <td>-0.619230</td>\n",
       "      <td>-0.928068</td>\n",
       "      <td>0.405024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248724</td>\n",
       "      <td>18.694990</td>\n",
       "      <td>asia</td>\n",
       "      <td>1.703196</td>\n",
       "      <td>-11.552129</td>\n",
       "      <td>0.381768</td>\n",
       "      <td>-3.550471</td>\n",
       "      <td>-0.055180</td>\n",
       "      <td>-3.344490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0         x1         x2         x3         x4         x5        x6  \\\n",
       "0  0.963686   6.627185 -45.224008   9.477531  -3.216532  13.216874  9.754747   \n",
       "1 -1.770062 -23.610459  -0.964003 -31.981497 -10.294599 -10.240251 -1.518888   \n",
       "2  9.962401  -8.349849  23.248891 -24.196879   8.937480  10.965000 -7.490596   \n",
       "3 -5.780709 -25.261584   1.383115 -11.786929   7.993078 -11.245752 -2.607351   \n",
       "4  1.211541   1.119963   7.512938  21.987312  -5.155392  10.339416  3.045180   \n",
       "\n",
       "         x7        x8        x9  ...       x91        x92   x93       x94  \\\n",
       "0  5.245851 -1.102918 -2.867482  ...  0.988829   0.313772  asia  1.380664   \n",
       "1 -1.675208  0.498134 -0.614390  ... -2.162863   1.809807  asia  2.500590   \n",
       "2 -3.025094  0.595807  0.382732  ...  1.779660   9.528113  asia  1.396475   \n",
       "3 -3.513896 -0.614235 -1.453979  ... -0.203206   4.892248  asia  0.744317   \n",
       "4 -0.619230 -0.928068  0.405024  ...  0.248724  18.694990  asia  1.703196   \n",
       "\n",
       "         x95        x96       x97       x98       x99  y  \n",
       "0 -16.388994   5.326730  4.187294  0.045549 -3.646841  0  \n",
       "1   4.338834  -1.583225 -1.172417  0.011216  0.097180  0  \n",
       "2   7.839188  10.402396  1.288991  0.008209 -4.132316  0  \n",
       "3   7.380982   7.599323 -8.022884 -0.067624 -1.796198  0  \n",
       "4 -11.552129   0.381768 -3.550471 -0.055180 -3.344490  0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading data\n",
    "raw_train_df=pd.read_csv(directory_train)\n",
    "raw_test_df=pd.read_csv(directory_test)\n",
    "\n",
    "#from this point I will deal with train data first\n",
    "#inspect train data headings\n",
    "print(raw_train_df.dtypes.value_counts())\n",
    "raw_train_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99 rows unamed rows and 1 y class prediciton row.<br>\n",
    "  No information about rows provided so hard to provide intuition or domain expertise.<br>\n",
    "  Contains both categorical and numerical variables.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide into categorical and numerical\n",
    "num_train_df=raw_train_df.loc[:,raw_train_df.dtypes == np.float64]\n",
    "cat_train_df=raw_train_df.loc[:,raw_train_df.dtypes == np.object]\n",
    "y_train_df=raw_train_df[\"y\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volkswagon    12622\n",
      "Toyota        10968\n",
      "bmw            7262\n",
      "Honda          5174\n",
      "tesla          2247\n",
      "chrystler      1191\n",
      "nissan          326\n",
      "ford            160\n",
      "mercades         31\n",
      "chevrolet        11\n",
      "Name: x34, dtype: int64 \n",
      "\n",
      "wed          14820\n",
      "thurday      13324\n",
      "wednesday     5938\n",
      "thur          4428\n",
      "tuesday        884\n",
      "friday         517\n",
      "monday          53\n",
      "fri             26\n",
      "Name: x35, dtype: int64 \n",
      "\n",
      "$156.29     4\n",
      "$680.85     4\n",
      "$-370.55    4\n",
      "$-511.36    4\n",
      "$732.95     3\n",
      "           ..\n",
      "$-644.69    1\n",
      "$624.06     1\n",
      "$-269.37    1\n",
      "$-223.71    1\n",
      "$-751.03    1\n",
      "Name: x41, Length: 37817, dtype: int64 \n",
      "\n",
      "0.01%     9610\n",
      "-0.01%    9547\n",
      "0.0%      7876\n",
      "-0.0%     7674\n",
      "0.02%     2373\n",
      "-0.02%    2363\n",
      "-0.03%     279\n",
      "0.03%      243\n",
      "-0.04%      17\n",
      "0.04%       11\n",
      "Name: x45, dtype: int64 \n",
      "\n",
      "July       11114\n",
      "Jun         9317\n",
      "Aug         8170\n",
      "May         4744\n",
      "sept.       3504\n",
      "Apr         1629\n",
      "Oct          885\n",
      "Mar          407\n",
      "Nov          145\n",
      "Feb           48\n",
      "Dev           16\n",
      "January       12\n",
      "Name: x68, dtype: int64 \n",
      "\n",
      "asia       35384\n",
      "america     3167\n",
      "euorpe      1442\n",
      "Name: x93, dtype: int64 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x34</th>\n",
       "      <th>x35</th>\n",
       "      <th>x41</th>\n",
       "      <th>x45</th>\n",
       "      <th>x68</th>\n",
       "      <th>x93</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39992</td>\n",
       "      <td>39990</td>\n",
       "      <td>39996</td>\n",
       "      <td>39993</td>\n",
       "      <td>39991</td>\n",
       "      <td>39993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>37817</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>volkswagon</td>\n",
       "      <td>wed</td>\n",
       "      <td>$156.29</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>July</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>12622</td>\n",
       "      <td>14820</td>\n",
       "      <td>4</td>\n",
       "      <td>9610</td>\n",
       "      <td>11114</td>\n",
       "      <td>35384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               x34    x35      x41    x45    x68    x93\n",
       "count        39992  39990    39996  39993  39991  39993\n",
       "unique          10      8    37817     10     12      3\n",
       "top     volkswagon    wed  $156.29  0.01%   July   asia\n",
       "freq         12622  14820        4   9610  11114  35384"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at categorical data\n",
    "for cat in cat_train_df:\n",
    "    print(cat_train_df[cat].value_counts(),'\\n')\n",
    "    \n",
    "cat_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing values that are interchangable\n",
    "#chose to replace with wed fri thur as the other way around will create wedwednesday... wed is part of wednesday \n",
    "cat_train_df['x35'] = cat_train_df['x35'].replace('wednesday','wed', regex = True)\n",
    "cat_train_df['x35'] = cat_train_df['x35'].replace('friday','fri', regex = True)\n",
    "cat_train_df['x35'] = cat_train_df['x35'].replace('thurday','thur', regex = True)\n",
    "\n",
    "# has no real effect just for cosmetic reasons but fixing other cat values\n",
    "cat_train_df['x68'] = cat_train_df['x68'].replace('sept.','Sept', regex = True)\n",
    "cat_train_df['x68'] = cat_train_df['x68'].replace('January','Jan', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remaining of these are not actually categorical data.\n",
    "## converting to true numerical data and adding to raw_num_train_df\n",
    "num_train_df['x41'] = cat_train_df['x41'].replace('[/$]','', regex = True).astype(float)\n",
    "num_train_df['x45'] = cat_train_df['x45'].replace('[%]','', regex = True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping out of categorical\n",
    "cat_train_df.drop(['x41'],axis=1,inplace=True)\n",
    "cat_train_df.drop(['x45'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x34</th>\n",
       "      <th>x35</th>\n",
       "      <th>x68</th>\n",
       "      <th>x93</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chrystler</td>\n",
       "      <td>thur</td>\n",
       "      <td>Sept</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>volkswagon</td>\n",
       "      <td>thur</td>\n",
       "      <td>July</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bmw</td>\n",
       "      <td>thur</td>\n",
       "      <td>July</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nissan</td>\n",
       "      <td>thur</td>\n",
       "      <td>July</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>volkswagon</td>\n",
       "      <td>wed</td>\n",
       "      <td>Jun</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x34   x35   x68   x93\n",
       "0   chrystler  thur  Sept  asia\n",
       "1  volkswagon  thur  July  asia\n",
       "2         bmw  thur  July  asia\n",
       "3      nissan  thur  July  asia\n",
       "4  volkswagon   wed   Jun  asia"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking a look at cat variables pre label and one hot encoding\n",
    "cat_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize missing num and cat data first\n",
    "#msno.matrix(num_train_df)\n",
    "#print(\"number of rows with missing values\")\n",
    "#print(sum(num_train_df.apply(lambda x: sum(x.isnull().values), axis = 1)>0)+\n",
    "#     sum(cat_train_df.apply(lambda x: sum(x.isnull().values), axis = 1)>0))\n",
    "\n",
    "#msno.matrix(cat_train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Data is pretty clean low percentage of Nan in rows.<br>\n",
    " 806 out of 40000 or 2%<br>\n",
    " As instructions specifically ask to avoid data leakage imputation of numerical values <br>\n",
    " Performing splitting into test train before imputation preventing data leakage.<br>\n",
    " Categorical values will be simply filles with most common instance no need for splitting<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#substituting Nan in categorical data with most frequent data \n",
    "#Checked that NaN was not the most frequent no need to split as only 34 missing NaN and no\n",
    "#data leakage\n",
    "for cat in cat_train_df:\n",
    "    cat_train_df[cat].fillna(cat_train_df[cat].value_counts().index[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#imputing and scaling numerical data\n",
    "#imputer will only be used to fir training part of the training model\n",
    "#It will be applied to Train_train, Train_test,Test\n",
    "#same process will be done to scaling\n",
    "semi_raw_df=pd.concat([num_train_df, cat_train_df], axis = 1)\n",
    "x_train1,x_val1,y_train,y_val=split(semi_raw_df,y_train_df,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting into trained into cat and numerical before data prep and clean\n",
    "num_x_train_df=x_train1.loc[:,x_train1.dtypes == np.float64]\n",
    "cat_X_train_df=x_train1.loc[:,x_train1.dtypes == np.object]\n",
    "\n",
    "\n",
    "num_x_val_df=x_val1.loc[:,x_val1.dtypes == np.float64]\n",
    "cat_X_val_df=x_val1.loc[:,x_val1.dtypes == np.object] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting into nominal values\n",
    "Cat_dict={}\n",
    "one_labels_df=pd.DataFrame()\n",
    "Encoder = pre.OneHotEncoder()\n",
    "\n",
    "for cat in cat_X_train_df:\n",
    "    Lab_Encoder = pre.LabelEncoder()\n",
    "    one_labels_df[cat]= Lab_Encoder.fit_transform(cat_X_train_df[cat])\n",
    "    Cat_dict[cat]= Lab_Encoder\n",
    "    \n",
    "#One hot encoding\n",
    "one_train_df  = pd.DataFrame(Encoder.fit_transform(one_labels_df).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical values imputation using SimpleImpute\n",
    "imp = SimpleImputer()\n",
    "imp_num_x_train_df=pd.DataFrame(imp.fit_transform(num_x_train_df))\n",
    "\n",
    "#scaling num value\n",
    "scaling= pre.StandardScaler()\n",
    "scaled_num_x_train_df = pd.DataFrame(scaling.fit_transform(imp_num_x_train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating x_train and pkl dumping x_train y train\n",
    "x_train=pd.concat([scaled_num_x_train_df,one_train_df],axis=1)\n",
    "\n",
    "pickle_out = open(\"x_train.pickle\",\"wb\")\n",
    "pkl.dump(x_train, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y_train.pickle\",\"wb\")\n",
    "pkl.dump(y_train, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#one hot encoding the validation\n",
    "one_val_labels_df=pd.DataFrame()\n",
    "for cat in Cat_dict:\n",
    "    one_val_labels_df[cat]=Cat_dict[cat].transform(cat_X_val_df[cat])\n",
    "\n",
    "one_val_df=pd.DataFrame(Encoder.transform(one_val_labels_df).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing the Validation data set\n",
    "imp_num_x_val_df=pd.DataFrame(imp.transform(num_x_val_df))\n",
    "\n",
    "scaled_num_x_val_df = pd.DataFrame(scaling.transform(imp_num_x_val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating x_val and pkl dumping x_val y_val\n",
    "x_val=pd.concat([scaled_num_x_val_df,one_val_df],axis=1)\n",
    "\n",
    "pickle_out = open(\"x_val.pickle\",\"wb\")\n",
    "pkl.dump(x_val, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y_val.pickle\",\"wb\")\n",
    "pkl.dump(y_val, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This section will repeat the process for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                x0           x1           x2            x3           x4  \\\n",
      "count  9998.000000  9998.000000  9998.000000  10000.000000  9999.000000   \n",
      "mean      2.123389    -4.170347     0.429555     -1.670248     0.492788   \n",
      "std       9.689917    18.696344    21.030355     29.335529    20.076053   \n",
      "min     -35.502970   -79.642519   -78.549288   -122.923518   -75.801406   \n",
      "25%      -4.544092   -16.505208   -13.378986    -21.568207   -13.099560   \n",
      "50%       2.180901    -4.349082     0.474530     -1.660928     0.481522   \n",
      "75%       8.611017     8.366082    14.719134     18.196968    13.944449   \n",
      "max      43.060198    65.821750    75.474024    114.318448    76.851984   \n",
      "\n",
      "                x5           x6           x7           x8           x9  ...  \\\n",
      "count  9997.000000  9998.000000  9997.000000  9999.000000  9998.000000  ...   \n",
      "mean     -0.860844     0.051060    -0.016683    -0.363496     0.005506  ...   \n",
      "std      18.379462     6.784101     5.646885     1.631196     1.355688  ...   \n",
      "min     -70.261284   -25.321554   -20.933111    -6.074191    -5.283435  ...   \n",
      "25%     -13.433930    -4.478927    -3.808500    -1.459765    -0.930234  ...   \n",
      "50%      -0.929346     0.076134     0.000242    -0.376981     0.006821  ...   \n",
      "75%      11.717888     4.678114     3.780986     0.707752     0.930947  ...   \n",
      "max      64.906604    30.633576    19.517706     5.774202     4.951416  ...   \n",
      "\n",
      "               x89          x90          x91          x92          x94  \\\n",
      "count  9997.000000  9999.000000  9997.000000  9998.000000  9997.000000   \n",
      "mean      0.100974   -12.190311    -0.000346     0.002674    -0.041808   \n",
      "std       4.629505   132.224032     1.633924     7.250379     2.800192   \n",
      "min     -16.329673  -513.946435    -6.054264   -26.790400   -10.293635   \n",
      "25%      -2.980643   -99.766088    -1.101436    -4.883637    -1.940054   \n",
      "50%       0.096448    -9.334347    -0.017453     0.060955    -0.031209   \n",
      "75%       3.235533    77.270536     1.096911     4.910293     1.857493   \n",
      "max      17.603261   453.642526     6.582023    26.924198    10.687981   \n",
      "\n",
      "               x95          x96          x97          x98          x99  \n",
      "count  9998.000000  9997.000000  9996.000000  9997.000000  9998.000000  \n",
      "mean     -0.113442    -0.401266    -0.551964    -0.000314     0.174460  \n",
      "std       8.595103     9.313037     4.086671     0.059228     4.512774  \n",
      "min     -34.904434   -38.931309   -15.971753    -0.245034   -16.675771  \n",
      "25%      -5.861813    -6.626781    -3.299415    -0.040216    -2.875389  \n",
      "50%      -0.096713    -0.406752    -0.611772    -0.000571     0.170326  \n",
      "75%       5.633708     6.015215     2.212922     0.039039     3.218189  \n",
      "max      29.231365    32.395912    15.934448     0.241790    19.143428  \n",
      "\n",
      "[8 rows x 94 columns]\n"
     ]
    }
   ],
   "source": [
    "# An assumption is that test and train data are identical\n",
    "print(raw_test_df.describe())\n",
    "#divide into categorical and numerical\n",
    "num_test_df=raw_test_df.loc[:,raw_test_df.dtypes == np.float64]\n",
    "cat_test_df=raw_test_df.loc[:,raw_test_df.dtypes == np.object]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing values that are interchangable\n",
    "#chose to replace with wed fri thur as the other way around will create wedwednesday... wed is part of wednesday \n",
    "cat_test_df['x35'] = cat_test_df['x35'].replace('wednesday','wed', regex = True)\n",
    "cat_test_df['x35'] = cat_test_df['x35'].replace('friday','fri', regex = True)\n",
    "cat_test_df['x35'] = cat_test_df['x35'].replace('thurday','thur', regex = True)\n",
    "\n",
    "# has no real effect just for cosmetic reasons but fixing other cat values\n",
    "cat_test_df['x68'] = cat_test_df['x68'].replace('sept.','Sept', regex = True)\n",
    "cat_test_df['x68'] = cat_test_df['x68'].replace('January','Jan', regex = True)\n",
    "\n",
    "## remaining of these are not actually categorical data.\n",
    "## converting to true numerical data and adding to raw_num_train_df\n",
    "num_test_df['x41'] = cat_test_df['x41'].replace('[/$]','', regex = True).astype(float)\n",
    "num_test_df['x45'] = cat_test_df['x45'].replace('[%]','', regex = True).astype(float)\n",
    "\n",
    "#dropping out of categorical\n",
    "cat_test_df.drop(['x41'],axis=1,inplace=True)\n",
    "cat_test_df.drop(['x45'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#substituting Nan in categorical data with most frequent data \n",
    "for cat in cat_test_df:\n",
    "    cat_test_df[cat].fillna(cat_test_df[cat].value_counts().index[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wed        5199\n",
      "thur       4408\n",
      "tuesday     228\n",
      "fri         144\n",
      "monday       21\n",
      "Name: x35, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(cat_test_df['x35'].value_counts(dropna=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting into nominal values\n",
    "one_labels_test_df=pd.DataFrame()\n",
    "\n",
    "for cat in cat_test_df:\n",
    "    one_labels_test_df[cat]=Cat_dict[cat].transform(cat_test_df[cat])\n",
    "\n",
    "one_test_df=pd.DataFrame(Encoder.transform(one_labels_test_df).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing the testing data set\n",
    "imp_num_x_test_df=pd.DataFrame(imp.transform(num_test_df))\n",
    "\n",
    "#scaling\n",
    "scaled_num_x_test_df = pd.DataFrame(scaling.transform(imp_num_x_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating x_test and pkl dumping x_test y_test\n",
    "x_test=pd.concat([scaled_num_x_test_df,one_test_df],axis=1)\n",
    "\n",
    "pickle_out = open(\"x_test.pickle\",\"wb\")\n",
    "pkl.dump(x_test, pickle_out)\n",
    "pickle_out.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "error=pd.DataFrame((num_x_val_df.mean()-num_train_df.mean())/num_x_val_df.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    17.961966\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking correlaitons \n",
    "#and multicoriniarity \n",
    "\n",
    "correlated_data=x_train.corr().abs()\n",
    "corrMatrix=correlated_data[correlated_data>0.8].unstack().dropna(how=\"all\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   0     1.000000\n",
      "12  14    0.927503\n",
      "27  28    0.810152\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(corrMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
